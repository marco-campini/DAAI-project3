{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbMELCjQDniUm7L8z+Qu28"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# DAAI Project 3 - Train On GTA5 (step 2b)"],"metadata":{"id":"wqSuA0JRdf0_"}},{"cell_type":"markdown","source":["## Data Preparation"],"metadata":{"id":"a4NwOahNd3BS"}},{"cell_type":"markdown","source":["### Clone the professor's repository"],"metadata":{"id":"UC3g4BRSd7BP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"i6n37NsEaCTg"},"outputs":[],"source":["!git clone https://github.com/ClaudiaCuttano/AML_Semantic_DA.git"]},{"cell_type":"markdown","source":["### Mount Google Drive to access files"],"metadata":{"id":"8LC8moiId-7y"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"id":"OyF9yE5eaJft"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Replace the empty 'cityscapes.py' with the one in this repo"],"metadata":{"id":"v0WSHE7_eB_s"}},{"cell_type":"code","source":["# when training with transforms copy GTA_transforms.py instead of GTA.py\n","!cp datasets/GTA.py AML_Semantic_DA/cityscapes.py"],"metadata":{"id":"WkSUhtubaWcF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Extract the GTA5 dataset"],"metadata":{"id":"NXQ1dRjievup"}},{"cell_type":"code","source":["import zipfile\n","\n","with zipfile.ZipFile(f'drive/MyDrive/GTA5.zip', 'r') as zip_ref:\n","  zip_ref.extractall()"],"metadata":{"id":"zztPzgjIaYKF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Copy the pre-trained model to Colab"],"metadata":{"id":"xASkL1Gse2z5"}},{"cell_type":"code","source":["!cp drive/MyDrive/STDCNet813M_73.91.tar STDCNet813M_73.91.tar"],"metadata":{"id":"dn6thoVdaZ3X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Install tensorboardX"],"metadata":{"id":"4bcoFMAWe5hz"}},{"cell_type":"code","source":["!pip install tensorboardX"],"metadata":{"id":"6toch693acHm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Split the GTA5 dataset into train and val"],"metadata":{"id":"HznXM4yCe85V"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import shutil\n","import os\n","\n","test_size = 0.3\n","img_dir = 'GTA5/images'\n","\n","all_files = os.listdir(img_dir)\n","\n","# use random_state to always have the same images in train and val\n","train_files, test_files = train_test_split(all_files, test_size=test_size, random_state=10)\n","\n","train_folder = os.path.join(img_dir, 'train')\n","test_folder = os.path.join(img_dir, 'val')\n","\n","os.makedirs(train_folder, exist_ok=True)\n","os.makedirs(test_folder, exist_ok=True)\n","os.makedirs(train_folder.replace('images', 'labels'), exist_ok=True)\n","os.makedirs(test_folder.replace('images', 'labels'), exist_ok=True)\n","\n","for img in train_files:\n","    source_path = os.path.join(img_dir, img)\n","    destination_path = os.path.join(train_folder, img)\n","    shutil.move(source_path, destination_path)\n","    shutil.move(source_path.replace('images', 'labels'), destination_path.replace('images', 'labels'))\n","\n","for img in test_files:\n","    source_path = os.path.join(img_dir, img)\n","    destination_path = os.path.join(test_folder, img)\n","    shutil.move(source_path, destination_path)\n","    shutil.move(source_path.replace('images', 'labels'), destination_path.replace('images', 'labels'))"],"metadata":{"id":"mouN3quUdLWE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train the model"],"metadata":{"id":"T-W0PVPDfp2k"}},{"cell_type":"code","source":["!python AML_Semantic_DA/train.py \\\n","--save_model_path drive/MyDrive/GTA5/ \\\n","--backbone STDCNet813 \\\n","--mode train \\\n","--pretrain_path STDCNet813M_73.91.tar \\\n","--num_workers 2 \\\n","--num_epochs 20 \\\n","--batch_size 2 \\\n","--validation_step 5 \\\n","--learning_rate 0.000302 \\\n","--checkpoint_step 5"],"metadata":{"id":"3byS5PeKad1c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualize The Results"],"metadata":{"id":"1dHa-XENgePI"}},{"cell_type":"markdown","source":["### Create dataset and dataloader"],"metadata":{"id":"W6zIOaPZghgW"}},{"cell_type":"code","source":["from pathlib import Path\n","from torch.utils.data import DataLoader\n","import os\n","import matplotlib.pyplot as plt\n","from AML_Semantic_DA.cityscapes import CityScapes\n","\n","\n","BATCH_SIZE = 1\n","NUM_WORKERS = os.cpu_count()\n","num_classes = 19\n","\n","val_dataset = CityScapes(\n","    mode='val'\n","    )\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=BATCH_SIZE,\n","    num_workers=NUM_WORKERS,\n","    shuffle=True\n",")"],"metadata":{"id":"TgJCKxFyfwpW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load the trained model"],"metadata":{"id":"nhNlmMWyhNyO"}},{"cell_type":"code","source":["from AML_Semantic_DA.model.model_stages import BiSeNet\n","import torch\n","\n","model = BiSeNet(backbone='STDCNet813', n_classes=num_classes, pretrain_model='STDCNet813M_73.91.tar', use_conv_last=False)\n","model.load_state_dict(torch.load('drive/MyDrive/GTA5/best.pth', map_location='cpu'))\n","model = torch.nn.DataParallel(model).cuda()"],"metadata":{"id":"ZKjEJKILhQ6z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Get an image and its label"],"metadata":{"id":"wvQW8b4BhbVN"}},{"cell_type":"code","source":["data, label = next(iter(val_loader))"],"metadata":{"id":"mZk804tXhann"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Generate prediction and calculate metrics"],"metadata":{"id":"b4493Y9YhfTc"}},{"cell_type":"code","source":["import numpy as np\n","from AML_Semantic_DA.utils import poly_lr_scheduler\n","from AML_Semantic_DA.utils import reverse_one_hot, compute_global_accuracy, fast_hist, per_class_iu\n","\n","with torch.no_grad():\n","  model.eval()\n","  hist = np.zeros((num_classes, num_classes))\n","  label = label.type(torch.LongTensor)\n","  data = data.cuda()\n","  label = label.long().cuda()\n","\n","  # get RGB predict image\n","  predict, _, _ = model(data)\n","  predict = predict.squeeze(0)\n","  predict = reverse_one_hot(predict)\n","  predict = np.array(predict.cpu())\n","\n","  # get RGB label image\n","  label = label.squeeze()\n","  label = np.array(label.cpu())\n","\n","  # compute per pixel accuracy\n","  precision = compute_global_accuracy(predict, label)\n","  hist += fast_hist(label.flatten(), predict.flatten(), num_classes)\n","\n","  precision = np.mean(precision_record)\n","  miou_list = per_class_iu(hist)\n","  miou = np.mean(miou_list)\n","  print('precision per pixel for test: %.3f' % precision)\n","  print('mIoU for validation: %.3f' % miou)\n","  print(f'mIoU per class: {miou_list}')"],"metadata":{"id":"ddGyYe1Qhi6S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Show the pictures"],"metadata":{"id":"AXBbaUfhhtlr"}},{"cell_type":"code","source":["plt.imshow(data[0].permute(1,2,0).cpu())"],"metadata":{"id":"Ik19TXkhhlZh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label[label==255] = 0\n","plt.imshow(label)"],"metadata":{"id":"xa2lfgcehxKy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(predict)"],"metadata":{"id":"G452nXXthx2F"},"execution_count":null,"outputs":[]}]}